# -*- coding: utf-8 -*-
"""Final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1icxI6qN7FPBkp4_tI-xz0MQy0voXNzfe

<img src="https://pure.ups.edu.ec/skin/footerIcon/"/>

**Nombres:**  Wilmer John Durazno Zapatanga

**Tema:**  Reforzar e integrar todos los conocimientos adquiridos sobre técnicas de aprendizaje de máquina

1.	Describir el dataset

En el problema del Dataset se encuentra en los clientes de un banco el cual contiene 18 campos con 1000 instancias.
EN el campo Objetivo se refiere en que si el cliente es bueno o malo, el cual tiene los valores 1 como bueno y 2 como malo.

* Los campos que contienen son los siguientes:

    1.1. DNI o identificacion

    1.2. PLAZO MESES CREDITO

    1.3. HISTORIAL CREDITO

    1.4. PROPOSITO CREDITO

    1.5. MONTO CREDITO

    1.6. SALDO CUENTA AHORROS

    1.7. TIEMPO EMPLEO

    1.8. TASA PAGO

    1.9. ESTADO CIVIL Y SEXO

    1.10. GARANTE

    1.11. AVALUO VIVIENDA

    1.12. ACTIVOS

    1.13. EDAD

    1.14. VIVIENDA

    1.15. CANTIDAD CREDITOS EXISTENTES

    1.16. EMPLEO 

    1.17.TRABAJADOR EXTRANJERO
    
    1.18. TIPO CLIENTE (1=bueno 2=malo)

2.	Realizar el procesamiento
3.	Dividir variables independientes X, y variable dependiente Y (la salida, que es la última columna del archivo). La salida se llama “TIPOCLIENTE”. 1 significa buen cliente (bajo riesgo) y 2 mal cliente (mucho riesgo).
4.	Realizar splitting en train (80%) y test (20%) 
5.	Realizar un aprendizaje de máquina mediante clasificación con una red neuronal estándar (SNN)
6.	Realizar un aprendizaje de máquina mediante clasificación con una SVM
7.	Medir el RMSE de cada modelo
8.	Comparar el RMSE entre SNN y SVM. Llenar la siguiente tabla con los resultados.
9. Realizar la predicción usando la Red Neuronal. Se debe crear una función predecir (DNI=”id_dni”), que retorne el resultado de predicción. 
10. Generar conclusiones, recomendaciones y referencias
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import make_column_transformer, ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split

df = pd.read_csv('DatasetBanco.csv',';')
df.head()

df = df.dropna(subset=['DNI'])
#df.head()

df.dtypes

Xsubset = df[['DNI']]

#Xsubset.fillna(0)

#para separar nuestra variable dependiente de la independiente, haremos lo siguiente:

y = df.TIPOCLIENTE.values
print(Xsubset)
type(Xsubset)

"""Preprocesamiento

"""

#PRIMERA FORMA DE PREPROCESAR

preprocesador1 = make_column_transformer(
    (StandardScaler(),['DNI']),
    (OneHotEncoder(),['DNI']))

#ordinal(importa el orden): OneHotEncoder -> sistema binario
#nominal(No importa el orden, importa la clase o el nombre): Encoder Simple 

X = preprocesador1.fit_transform(Xsubset)

categorical_features = ['DNI']
cnamesDataset1 = ['DNI']
cnamesDataset2 = preprocesador1.transformers_[1][1].get_feature_names(categorical_features)


cnamesDataset1.extend(cnamesDataset2)
DatasetPreprocesado = pd.DataFrame(X.toarray())
#DatasetPreprocesado = pd.DataFrame(data=X,columns=cnamesDataset1)
DatasetPreprocesado.columns = cnamesDataset1
print(DatasetPreprocesado.head())

DatasetPreprocesado.to_csv("DatasetPreprocesado.csv", sep=";",index = False) #sep es el separado, por defector es ","

"""Train y Test"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)

#Ahora preparamos el perceptron. Importamos las neuronas simples y el modelo secuencial
#Modelo secuencial quiere decir que agregaremos capas y se conectarán de manera automática, 
#Dense es la librería de neuronas simples.
import keras
from keras.layers import Dense
from keras.models import Sequential
from keras.models import model_from_json
print('Librerías importadas')

X_train.shape[1]

"""# DISENO SNN

ALMACENAMIENTO Y CARGA DE MODELOS DE REDES NEURONALES
"""

#FUNCIONES PARA GuARDAR Y CARGAR CUALQUIER MODELO

#Guardar pesos y la arquitectura de la red en un archivo 

def guardarRNN(model,nombreArchivoModelo,nombreArchivoPesos):
    print("Guardando Red Neuronal en Archivo")  
    # serializar modelo a JSON

    # Guardar los Pesos (weights)
    model.save_weights(nombreArchivoPesos+'.h5')

    # Guardar la Arquitectura del modelo
    with open(nombreArchivoModelo+'.json', 'w') as f:
        f.write(model.to_json())

    print("Red Neuronal Grabada en Archivo")   
    
def cargarRNN(nombreArchivoModelo,nombreArchivoPesos):
        
    # Cargar la Arquitectura desde el archivo JSON
    with open(nombreArchivoModelo+'.json', 'r') as f:
        model = model_from_json(f.read())

    # Cargar Pesos (weights) en el nuevo modelo
    model.load_weights(nombreArchivoPesos+'.h5')  

    print("Red Neuronal Cargada desde Archivo") 
    return model

#Construcción del Modelo o Arquitectura de Redes Neoronales
model = Sequential()

model.add(Dense(32, input_shape=(X_train.shape[1],), activation='relu'))
model.add(Dense(64, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

model.compile(loss='binary_crossentropy', optimizer='adadelta', metrics=['acc']) #ADADELTA: An Adaptive Learning Rate Method

#imprimir arquitectura de la red
model.summary()

model.fit(X_train, y_train, epochs=100, batch_size=64, verbose=0)
score = model.evaluate(X_train, y_train, verbose=0)
print('Resultado en Train:')
print("%s: %.2f%%" % (model.metrics_names[1], score[1]*100))

#Fase de Testing
score = model.evaluate(X_test, y_test, verbose=0)
print('Resultado en Test:')
print("%s: %.2f%%" % (model.metrics_names[1], score[1]*100))


nombreArchivoModelo='arquitectura_prueba'
nombreArchivoPesos='pesos_prueba'
guardarRNN(model,nombreArchivoModelo,nombreArchivoPesos)

#Cargar pesos y la arquitectura
model2=cargarRNN(nombreArchivoModelo,nombreArchivoPesos) 

model2.compile(loss='binary_crossentropy', optimizer='adadelta', metrics=['acc']) #ADADELTA: An Adaptive Learning Rate Method
score = model2.evaluate(X_train, y_train, verbose=0)
print('Resultado en Train:')
print("%s: %.2f%%" % (model2.metrics_names[1], score[1]*100))

#Fase de Testing
print('Resultado en Test:')
score = model2.evaluate(X_test, y_test, verbose=0)
print("%s: %.2f%%" % (model2.metrics_names[1], score[1]*100))

test_acc_snn = model.evaluate(X_test, y_test, verbose=0)

acc_snn=str(round(test_acc_snn[1], 4))
print('\nSNN Accuracy: ',acc_snn)

#Predicciones del conjunto de Test
y_pred = model.predict_classes(X_test)

#Comparación de algunas predicciones
print(y_pred[100:106])
print(y_test[100:106])

from sklearn.metrics import zero_one_loss

error_rate_snn = zero_one_loss(y_test,y_pred)
error_rate_snn=str(round(error_rate_snn, 4))
print("Error rate (%): ",error_rate_snn)

"""# DISENIO SVM

"""

from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
print('SVM Classifier with gamma = 0.1; Kernel = Polynomial')
classifier = SVC(gamma=0.1, kernel='poly', C=1.0, random_state = 0, verbose=True)

classifier.fit(X_train,y_train)

#Predicciones del conjunto de Test
y_pred = classifier.predict(X_test)

model_acc = classifier.score(X_test, y_test)
test_acc_svm = accuracy_score(y_test, y_pred) #accuracy_score hace lo mismo que la función score

acc_svm=str(round(test_acc_svm, 4))
print('\nSVM Accuracy con classifier.score: ', str(round(model_acc, 4)))
print('\nSVM Accuracy con accuracy_score: ', acc_svm)

#Comparación de algunas predicciones
print(y_pred[100:106])
print(y_test[100:106])

from sklearn.metrics import zero_one_loss

error_rate_svm = zero_one_loss(y_test,y_pred)
error_rate_svm=str(round(error_rate_svm, 4))
print("Error rate (%): ",error_rate_svm)

"""Comparar el RMSE entre SNN y SVM."""

import pandas as pd
tabla = pd.DataFrame(columns=('tipo', 'accuracy','tasa de error'))

tabla.loc[len(tabla)]=['SNN',acc_snn,error_rate_snn] 
tabla.loc[len(tabla)]=['SVM',acc_svm,error_rate_svm]

tabla.head()

"""Prediccion"""

#Predicciones con nuevos datos

def predict(DNI=104600006):
    cnames = ['DNI']
    data = [[DNI]]
    my_X = pd.DataFrame(data=data, columns=cnames)
    my_X = preprocesador1.transform(my_X)
    return model.predict_classes(my_X)

if (predict==[[2]]):
  print('El cliente ha sido clasificado como buen cliente. ')
else:
  print('El cliente ha sido clasificado como mal cliente. ')

"""**CONCLUCIONES**

Lasa siguiente prediccion realizada con lo siguintes aprendizaje de maquina de SVM Y SNN en el cual nos dio un accuracy muy buenos dentro de la tabla que se observa en la tabla de comparacion.

Al comparar en el RMSE no vemos que mo hay una gran diferencia en la taza de error, y al momento de la prediccion nos muestra una respuesta en que si los clientes son buenos o malos.

**RECOMENDACION**

Que de mi parte no se tubo pocas complicaciones al realizar el SNN y no se pudo profundizar y que al momento de realizar en la web no se pudo tener un exito al momento de cargar los pesos obtenidos de las consultal del dataset.

**REFERENCIA**



*   PYTHON MACHINE LEARNING "thirde Edition", "Machine learning and deep learning with python scikit-learn, and TensorFlow2
*   "Axel Aleman, se realizo hace 6 meses ", https://www.kaggle.com/axelalemn/prediccion-de-defunciones-por-covid-19
*   "Jeremy Howard, se leaizo hace 10 dias", https://www.kaggle.com/jhoward/nb-svm-strong-linear-baseline/comments
*   "Ahmet Erdem, se realizo hace 5 años ", https://www.kaggle.com/aerdem4/rapids-svm-on-trends-neuroimaging
*   "Guang Yang 0528, se realizo hace 3 meses ", https://www.kaggle.com/sunny0528/whale-identification-snn
*   "Jessye Pedraja, se realizo hace 25 dias", https://www.kaggle.com/jessyepedraja/cibercrimen-predicciones-espa-a-2020
*   "Viking Pathak, se realizo hace 4 dias", https://www.kaggle.com/vikingpathak/rmse-0-09-extensive-data-exploration-a-z
"""

#!jupyter nbconvert --to html Final.ipynb